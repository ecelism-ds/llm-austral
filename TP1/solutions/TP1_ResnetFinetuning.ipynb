{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732fa26b-e6c2-4bbf-b37e-71971699f94e",
   "metadata": {},
   "source": [
    "Para ello ya escribimos un Dataset particular que lee el CSV y dado el índice de un ejemplo, calcula la posición de la cabeza, carga la imágen y retorna el par (imagen, posición) que para nuestro problema constituirán el par (x,y) (feature o variable independiente, target o variable dependiente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c9cb46-184f-41dc-9b83-1964e96ba1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.models\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d8c256-8554-421e-b4d2-32bb3665195a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.DEFAULT)\n",
    "resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "705c5d65-6554-49a5-9f98-494c039a0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9220d754-5fa9-45a8-b554-87d953381e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=10, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c714f48b-391e-40c5-98c4-38eafee4d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "# Los arrays de las imagenes fueron guardados en un archivo formato pickle, que se utiliza para persistir variable en Python\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1139631c-ae5f-4ed1-9128-b28bde91082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7628d9e-2d0a-48bf-91ae-0d9107302843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3, 28, 28), (10000, 3, 28, 28))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_channels(x):\n",
    "    x=x.reshape(-1,28,28)\n",
    "    x=np.stack([x,x,x],axis=1)\n",
    "    return x\n",
    "x_train=add_channels(x_train)\n",
    "x_valid=add_channels(x_valid)\n",
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe169346-5889-4b89-9373-43ddc3ffeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(probs, target):\n",
    "    class_predictions = torch.argmax(probs, dim=1)\n",
    "    return (class_predictions == target).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b59dabe-886a-4688-ba59-6388aff4daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.tensor(x_train), torch.tensor(y_train))\n",
    "valid_dataset = TensorDataset(torch.tensor(x_valid), torch.tensor(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5827dfb-79fc-49c5-b611-71b44ad42420",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f32c05d-9f3f-4aa4-a854-04763678d85a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=next(iter(train_dataloader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4cfdd07-2e7c-4b9a-a720-50ca8439a522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=resnet_model(x)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4debf07-46e7-448f-89c2-b274096bb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88f9c9f9-b41e-4197-8b6b-24f7da8ba054",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = list(resnet_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a1d82a8-a578-42ba-8ad5-76fec2c96374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(ws, unfreeze=False):\n",
    "    for w in ws:\n",
    "        w.requires_grad=unfreeze\n",
    "freeze(all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dc2e7e1-ddfc-4962-a761-c52b67eca431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.fc.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebad8fa8-3397-4221-8e43-97382e7c9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze(resnet_model.fc.parameters(),unfreeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9d9921-349f-4e3d-a6ce-8b7612953da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.fc.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38c6d746-1236-4303-8f23-94078ebbbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_only_fc = torch.optim.Adam(resnet_model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a538f5d-5d5a-480c-b93d-e962a33f8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "resnet_model = resnet_model.to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3692da97-4e1b-4c3f-ac08-a0fea18cca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, opt):\n",
    "    for idx_epoch in range(n_epochs):\n",
    "        # Loop de entrenamiento\n",
    "        loss_train_sum = 0\n",
    "        n_batches_train = 0\n",
    "        resnet_model.train()\n",
    "        for x_train_batch, y_train_batch in tqdm(train_dataloader):\n",
    "            x_train_batch = x_train_batch.to(mps_device)\n",
    "            y_train_batch = y_train_batch.to(mps_device)\n",
    "            predictions = resnet_model(x_train_batch)\n",
    "            loss = loss_fn(predictions, y_train_batch)\n",
    "            loss_train_sum += loss.item()\n",
    "            n_batches_train += 1\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    \n",
    "        # Evaluamos los datos en validación\n",
    "        loss_validation_sum = 0\n",
    "        accuracy_sum = 0\n",
    "        n_batches_valid = 0\n",
    "        resnet_model.eval()\n",
    "        for x_valid_batch, y_valid_batch in tqdm(valid_dataloader):\n",
    "            x_valid_batch = x_valid_batch.to(mps_device)\n",
    "            y_valid_batch = y_valid_batch.to(mps_device)\n",
    "            predictions = resnet_model(x_valid_batch)\n",
    "            loss = loss_fn(predictions, y_valid_batch)\n",
    "            loss_validation_sum += loss.item()\n",
    "            accuracy_sum += accuracy(predictions, y_valid_batch).item()\n",
    "            n_batches_valid += 1\n",
    "        \n",
    "        # Imprimimos el loss en train y validación y la métrica (siempre en validación)\n",
    "        accuracy_validation = accuracy_sum / n_batches_valid\n",
    "        loss_validation = loss_validation_sum / n_batches_valid\n",
    "        train_validation = loss_train_sum / n_batches_train\n",
    "        print(f'epoch {idx_epoch} | train loss {loss_validation} | validation loss {train_validation} | accuracy {accuracy_validation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cca4b98c-c029-4bb9-ac3a-d47e6c584306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 1563/1563 [00:21<00:00, 74.21it/s]\n",
      "100%|█████████████████████████| 313/313 [00:03<00:00, 87.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | train loss 0.7218840053668037 | validation loss 0.9062333932803063 | accuracy 0.7687699680511182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 1563/1563 [00:19<00:00, 80.26it/s]\n",
      "100%|█████████████████████████| 313/313 [00:03<00:00, 88.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train loss 0.7194936341180588 | validation loss 0.732578944650813 | accuracy 0.7655750798722045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 1563/1563 [00:20<00:00, 78.02it/s]\n",
      "100%|█████████████████████████| 313/313 [00:03<00:00, 91.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | train loss 0.6767344293883815 | validation loss 0.7192259843789532 | accuracy 0.7822484025559105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(3,optimizer_only_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c93007e5-07f1-4ff7-b6ee-0f385d1a562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze(resnet_model.parameters(),unfreeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c04c1170-424b-4a26-8cbd-e59125a57496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.conv1.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3395cb7a-e1e0-49cd-b0bb-26e35ae4dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb2df06e-fcae-48fb-a9e6-fb0425700040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 1563/1563 [01:32<00:00, 16.88it/s]\n",
      "100%|█████████████████████████| 313/313 [00:03<00:00, 85.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | train loss 0.08062260638633832 | validation loss 0.15287834833905975 | accuracy 0.981729233226837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 1563/1563 [01:31<00:00, 17.05it/s]\n",
      "100%|█████████████████████████| 313/313 [00:03<00:00, 92.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train loss 0.09859171823357431 | validation loss 0.11210157837327993 | accuracy 0.9720447284345048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 1563/1563 [01:31<00:00, 17.17it/s]\n",
      "100%|█████████████████████████| 313/313 [00:03<00:00, 89.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | train loss 0.049777310070828695 | validation loss 0.05895828608668815 | accuracy 0.9848242811501597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(3,optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
