{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivFEtAEZFKVq",
        "outputId": "3f2347d6-fb4f-4c14-ed8b-307f55133014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfvI23MqFfKp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = ''\n",
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js3dgZrAFf4E"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Cuantos equipos participaron en el mundial de futbol 2018?\"},\n",
        "  ],\n",
        "    seed=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6StpmihMGFsI",
        "outputId": "8cb7adf3-41a9-4746-80e0-40d340f68a39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-ANQlCeqzsP4zI8huUCXKZKbeLXM3M', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='32 equipos participaron en el Mundial de Fútbol 2018, celebrado en Rusia.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730147774, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=23, total_tokens=46, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7VwQRulwOya"
      },
      "source": [
        "** Llamadas a funciones**     \n",
        "\n",
        "Las llamadas a funciones de GPT permiten conectar los modelos con herramientas y sistemas externos. Esto es útil para numerosos casos de uso.\n",
        "\n",
        "**Ejercicio opcional:** Siguiendo el ejemplo brindado, crear tu propias funciones para potenciar al asistente.\n",
        "\n",
        "**Ejemplo:** Escribir funciones para:\n",
        "- Permitirle al asistente obtener datos en tiempo real de las condiciones climatológicas en una ubicación determinada. El Asistente deberá poder responder acertadamente a consultas como \"¿Cuál es actualmente la temperatura en México DF? Detallar otras condiciones climatológicas de ser posible\"\n",
        "- Permitirle al asistente buscar datos en tiempo real de cotizaciones de criptomonedas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qmyfnks10_1",
        "outputId": "8e7269ce-4227-4e59-f345-6976a5fb3200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hji-Fli1q06"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = ''\n",
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSqv9J1i1xLV"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Cuantos equipos participaron en el mundial de futbol 2018?\"},\n",
        "  ],\n",
        "    seed=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq_JJcsS1yR6",
        "outputId": "e1bb0ad0-c739-496d-f53d-2a74cf52b42b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-ANQmenvKtoTuwyywypPC3CaFNHRP4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='32 equipos participaron en el Mundial de Fútbol 2018.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730147864, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=23, total_tokens=40, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAeQsq1lzKsq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def get_weather(city):\n",
        "    api_key = '7663c30fc4c275ea5f373e7052d8a3d3'\n",
        "    url = f'http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric&lang=es'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        weather = {\n",
        "            'city': data['name'],\n",
        "            'temperature': data['main']['temp'],\n",
        "            'description': data['weather'][0]['main'],\n",
        "            'humidity': data['main']['humidity'],\n",
        "            'pressure': data['main']['pressure']\n",
        "        }\n",
        "        return weather\n",
        "    else:\n",
        "        return {'error': 'Weather data could not be found for the specified city.'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlxzfSk625Fs"
      },
      "outputs": [],
      "source": [
        "clima = get_weather('Mexico')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atnHfwV-3nPj",
        "outputId": "e702a4ca-cede-4c27-985d-6add87d64429"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'city': 'Mexico',\n",
              " 'temperature': 24.84,\n",
              " 'description': 'Clouds',\n",
              " 'humidity': 95,\n",
              " 'pressure': 1006}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDF61VS99amg",
        "outputId": "f5078762-cbbf-435d-c529-12f3d6225329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycoingecko\n",
            "  Downloading pycoingecko-3.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pycoingecko) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (2024.8.30)\n",
            "Downloading pycoingecko-3.1.0-py3-none-any.whl (8.8 kB)\n",
            "Installing collected packages: pycoingecko\n",
            "Successfully installed pycoingecko-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pycoingecko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW4Rk3JK3tQg"
      },
      "outputs": [],
      "source": [
        "from pycoingecko import CoinGeckoAPI\n",
        "\n",
        "def get_cryptocurrency_price(coin):\n",
        "    cg = CoinGeckoAPI()\n",
        "    data = cg.get_price(ids=coin.lower(), vs_currencies='usd')\n",
        "    if data:\n",
        "        price = data.get(coin.lower(), {}).get('usd')\n",
        "        if price:\n",
        "            return {'coin': coin.capitalize(), 'price_usd': price}\n",
        "    return {'error': 'Cound not find price for the specified cryptocurrency.'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoEgFBIj9OXO",
        "outputId": "77593c31-bf18-4f13-8660-0ee452bc7c77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'coin': 'Bitcoin', 'price_usd': 69884}"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_cryptocurrency_price('bitcoin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsDu2hDm9iP8"
      },
      "outputs": [],
      "source": [
        "def ask_gpt_with_tools(user_message):\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_weather\",\n",
        "                \"description\": \"Gets the current weather of a specific city.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"city\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Name of the city, for example, 'Mexico City'.\"\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"city\"],\n",
        "                    \"additionalProperties\": False,\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_crypto_price\",\n",
        "                \"description\": \"Gets the current price in USD of a specific cryptocurrency.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"currency\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Name of the cryptocurrency, for example, 'bitcoin', 'ethereum'.\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"currency\"],\n",
        "                    \"additionalProperties\": False,\n",
        "                },\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the supplied tools to assist the user.\"},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "\n",
        "\n",
        "    response = OpenAI.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=messages,\n",
        "        tools=tools\n",
        "    )\n",
        "\n",
        "    mensaje = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "    if mensaje.get(\"function_call\"):\n",
        "        nombre_funcion = mensaje[\"function_call\"][\"name\"]\n",
        "        argumentos_funcion = json.loads(mensaje[\"function_call\"][\"arguments\"])\n",
        "\n",
        "        if nombre_funcion == \"get_weather\":\n",
        "            resultado_funcion = get_weather(argumentos_funcion.get(\"ciudad\"))\n",
        "        elif nombre_funcion == \"get_cryptocurrency_price\":\n",
        "            resultado_funcion = get_cryptocurrency_price(argumentos_funcion.get(\"moneda\"))\n",
        "        else:\n",
        "            resultado_funcion = {'error': 'Función no reconocida.'}\n",
        "\n",
        "        # Añadimos el resultado de la función a la conversación\n",
        "        mensajes_adicionales = [\n",
        "            {\"role\": \"user\", \"content\": mensaje_usuario},\n",
        "            mensaje,\n",
        "            {\n",
        "                \"role\": \"function\",\n",
        "                \"name\": nombre_funcion,\n",
        "                \"content\": json.dumps(resultado_funcion, ensure_ascii=False),\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        respuesta_final = OpenAI.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0613\",\n",
        "            messages=mensajes_adicionales,\n",
        "        )\n",
        "\n",
        "        return respuesta_final[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return mensaje[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQUwQ74cEHdE"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Gets the current weather of a specific city.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"city\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Name of the city, for example, 'Mexico City'.\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"city\"],\n",
        "                \"additionalProperties\": False,\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_crypto_price\",\n",
        "            \"description\": \"Gets the current price in USD of a specific cryptocurrency.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"currency\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Name of the cryptocurrency, for example, 'bitcoin', 'ethereum'.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"currency\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljjE5NXef4EN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBflfyZYEnXj"
      },
      "source": [
        "**Ejercicio:** Programar un chat usando la API de OpenAI. El asistente debe \"guardar en memoria\" las interacciones previas con el usuario.\n",
        "Ejemplo:\n",
        "\n",
        "User: \"Me llamo Juan\".\n",
        "\n",
        "Assistant: \"Hola Juan!\".\n",
        "\n",
        "User: \"Cuál es mi nombre?\"\n",
        "\n",
        "Assistant: \"Tu nombre es Juan\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyXkYIJCMR2k",
        "outputId": "c2f44977-06dc-4a32-a649-b2aa459361b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting OpenAI\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from OpenAI) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from OpenAI)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from OpenAI)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->OpenAI)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (2.23.4)\n",
            "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, OpenAI\n",
            "Successfully installed OpenAI-1.52.2 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjVniaEAGvLc",
        "outputId": "04b7d293-d4de-4e34-b30c-a7efaac0029c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the OpenAI Chat! Type 'exit' to end the chat.\n",
            "\n",
            "User: Hi! My name is Jorge\n",
            "Assistant: Hello Jorge! How can I assist you today?\n",
            "\n",
            "User: I want to know a bit about argentinian mate. What is it?\n",
            "Assistant: Argentinian mate is a traditional South American drink made by infusing dried leaves of the yerba mate plant in hot water. Yerba mate is a species of holly native to South America, particularly Argentina, Uruguay, Paraguay, and southern Brazil. The drink is commonly referred to as just \"mate\" in Argentina and is typically consumed through a special straw called a bombilla from a hollowed-out gourd known as a mate cup.\n",
            "\n",
            "Mate is known for its strong, bitter flavor and high caffeine content, making it a popular choice for boosting energy and enhancing mental alertness. It is often enjoyed socially, with friends and family sharing a mate gourd and passing it around in a circle. Drinking mate is considered a deeply ingrained cultural practice in Argentina, and it is often associated with friendship, bonding, and relaxation.\n",
            "\n",
            "User: Thanks. Can you remember me my name?\n",
            "Assistant: Of course, your name is Jorge. Is there anything else I can help you with?\n",
            "\n",
            "User: exit\n",
            "Chat ended.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = ''\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "messages = []\n",
        "\n",
        "print(\"Welcome to the OpenAI Chat! Type 'exit' to end the chat.\\n\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower().strip() == \"exit\":\n",
        "            print(\"Chat ended.\")\n",
        "            break\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          messages=messages\n",
        "        )\n",
        "\n",
        "        assistant_message = response.choices[0].message.content.strip()\n",
        "\n",
        "        print(f\"Assistant: {assistant_message}\\n\")\n",
        "\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error ocurred: {e}\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMiaScBbaEO0",
        "outputId": "e0551dc1-941f-4ce7-f67b-bbe78ca5ba15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycoingecko\n",
            "  Downloading pycoingecko-3.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pycoingecko) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (2024.8.30)\n",
            "Downloading pycoingecko-3.1.0-py3-none-any.whl (8.8 kB)\n",
            "Installing collected packages: pycoingecko\n",
            "Successfully installed pycoingecko-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pycoingecko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tgdMKkpgaBlY"
      },
      "outputs": [],
      "source": [
        "from pycoingecko import CoinGeckoAPI\n",
        "\n",
        "def get_crypto_price(currency):\n",
        "    cg = CoinGeckoAPI()\n",
        "    data = cg.get_price(ids=currency.lower(), vs_currencies='usd')\n",
        "    if data:\n",
        "        price = data.get(currency.lower(), {}).get('usd')\n",
        "        if price:\n",
        "            return {'currency': currency.capitalize(), 'price_usd': price}\n",
        "    return {'error': 'Cound not find price for the specified cryptocurrency.'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZdW2UHLYaOWX"
      },
      "outputs": [],
      "source": [
        "def get_weather(city):\n",
        "    api_key = ''\n",
        "    url = f'http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric&lang=es'\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        weather = {\n",
        "            'city': data['name'],\n",
        "            'temperature': data['main']['temp'],\n",
        "            'description': data['weather'][0]['main'],\n",
        "            'humidity': data['main']['humidity'],\n",
        "            'pressure': data['main']['pressure']\n",
        "        }\n",
        "        return weather\n",
        "    else:\n",
        "        return {'error': 'Weather data could not be found for the specified city.'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHmRLUdrOWEm",
        "outputId": "0b3008b8-010b-469b-bc5b-9ab0fca50f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the OpenAI Chat with Function Calling! Type 'exit' to end the chat.\n",
            "\n",
            "User: i want to know mexico weather\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bLjXIuc2WAxiuLqmhpzsyN9M', function=Function(arguments='{\"city\":\"Mexico City\"}', name='get_weather'), type='function')])\n",
            "\n",
            "Assistant is calling function: get_weather with arguments {'city': 'Mexico City'}\n",
            "\n",
            "Assistant: The current weather in Mexico City is 22.75°C with cloudy skies. The humidity is at 41% and the atmospheric pressure is 1016 hPa.\n",
            "\n",
            "User: and the weather in rosario?\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7lztDK9SmcLb8hmJTkPHBI4F', function=Function(arguments='{\"city\":\"Rosario\"}', name='get_weather'), type='function')])\n",
            "\n",
            "Assistant is calling function: get_weather with arguments {'city': 'Rosario'}\n",
            "\n",
            "Assistant: The current weather in Rosario is 31.55°C with clear skies. The humidity is at 45% and the atmospheric pressure is 1011 hPa.\n",
            "\n",
            "User: exit\n",
            "Chat ended.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Gets the current weather of a specific city.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"city\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Name of the city, for example, 'Mexico City'.\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"city\"],\n",
        "                \"additionalProperties\": False,\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_crypto_price\",\n",
        "            \"description\": \"Gets the current price in USD of a specific cryptocurrency.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"currency\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Name of the cryptocurrency, for example, 'bitcoin', 'ethereum'.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"currency\"],\n",
        "                \"additionalProperties\": False,\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "messages = []\n",
        "\n",
        "print(\"Welcome to the OpenAI Chat with Function Calling! Type 'exit' to end the chat.\\n\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Chat ended.\")\n",
        "            break\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",  # Use a model that supports function calling\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "        )\n",
        "\n",
        "        # Extract the assistant's message\n",
        "        assistant_message = response.choices[0].message\n",
        "\n",
        "        print(assistant_message)\n",
        "\n",
        "        # Check if the assistant wants to call a function\n",
        "        if assistant_message.tool_calls:\n",
        "            tool_call = assistant_message.tool_calls[0]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_name = tool_call.function.name\n",
        "\n",
        "            print(f\"\\nAssistant is calling function: {function_name} with arguments {function_args}\\n\")\n",
        "\n",
        "            # Call the appropriate function based on the function name\n",
        "            if function_name == \"get_weather\":\n",
        "                function_response = get_weather(**function_args)\n",
        "            elif function_name == \"get_crypto_price\":\n",
        "                function_response = get_crypto_price(**function_args)\n",
        "            else:\n",
        "                function_response = {\"error\": \"Function not recognized.\"}\n",
        "\n",
        "            # Convert the function response to a JSON-formatted string\n",
        "            function_response_json = json.dumps(function_response)\n",
        "\n",
        "            # Append the assistant's function call and the function's response to the messages\n",
        "            messages.append(assistant_message)  # Assistant's function call\n",
        "            function_call_result_message = {\n",
        "                \"role\": \"tool\",\n",
        "                \"content\": function_response_json,\n",
        "                \"tool_call_id\": tool_call.id\n",
        "            }\n",
        "            messages.append(function_call_result_message)\n",
        "\n",
        "            # Get the assistant's final response using the function's output\n",
        "            second_response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=messages\n",
        "            )\n",
        "\n",
        "            # Extract and print the assistant's final answer\n",
        "            final_answer = second_response.choices[0].message.content\n",
        "            print(f\"Assistant: {final_answer}\\n\")\n",
        "\n",
        "            # Append the final answer to the conversation\n",
        "            messages.append({\"role\": \"assistant\", \"content\": final_answer})\n",
        "        else:\n",
        "            # If no function call, just print the assistant's response\n",
        "            assistant_content = assistant_message.content.strip()\n",
        "            print(f\"Assistant: {assistant_content}\\n\")\n",
        "            messages.append(assistant_message)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        break\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
